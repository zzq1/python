{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957530864198\n",
      "[ 0.01677054  0.01677054  0.01677054 ...,  0.7         0.7         0.7       ]\n",
      "AUC Score (Train): 0.897424\n",
      "准确率 0.112449799197\n",
      "F1= 0.202166064982\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=True, random_state=20, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.py:403: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifier\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.grid_search import GridSearchCV  \n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "train=pd.read_csv(\"C:/Users/zzq/Desktop/DataMining/Data/train.csv\")\n",
    "test=pd.read_csv(\"C:/Users/zzq/Desktop/DataMining/Data/test.csv\")\n",
    "train_x = train.iloc[:,[2,3,4,5,6,7,8,9,10,11,12,13]]\n",
    "train_y = train.loc[:,[\"Catrgory\"]]\n",
    "test_x = test.iloc[:,[2,3,4,5,6,7,8,9,10,11,12,13]]\n",
    "test_y = test.loc[:,[\"Catrgory\"]]\n",
    "#不管任何参数，都用默认的，拟合下数据看看  \n",
    "rf0 = RandomForestClassifier(oob_score=True, random_state=20, max_depth = 7)  \n",
    "#rf0.fit(trainSet,train_lable)  \n",
    "rf0.fit(train_x,train_y)\n",
    "print rf0.oob_score_  \n",
    "#y_predprob = rf0.predict_proba(trainSet)[:,1]  \n",
    "y_predprob = rf0.predict_proba(test_x)[:,1]  \n",
    "print y_predprob\n",
    "print \"AUC Score (Train): %f\" % metrics.roc_auc_score(test_y,y_predprob)\n",
    "\n",
    "from __future__ import division\n",
    "test[\"predict\"] = y_predprob\n",
    "PrecisionSet=test[test.predict >= 0.5]\n",
    "ConnectSet = PrecisionSet[(PrecisionSet[\"Catrgory\"]== 1) & (PrecisionSet[\"Catrgory\"] >= 0.5)]\n",
    "ReferenceSet = PrecisionSet[PrecisionSet[\"Catrgory\"]== 1]\n",
    "presicion = len(ConnectSet) / len(PrecisionSet)\n",
    "print \"准确率\",presicion\n",
    "recall = len(ConnectSet)/ len(ReferenceSet)\n",
    "F1 = 2*presicion*recall / (presicion+recall) \n",
    "print \"F1=\",F1\n",
    "print rf0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id      item_id  brows_count  collect_count  add_count  buy_count  \\\n",
      "0       492.0   31040941.0          2.0            0.0        0.0        0.0   \n",
      "1  19445510.0   31040941.0          2.0            0.0        0.0        0.0   \n",
      "2  47308508.0   31040941.0          2.0            0.0        0.0        0.0   \n",
      "3  47308508.0  173394740.0          2.0            0.0        0.0        0.0   \n",
      "4  47308508.0   62138860.0          1.0            0.0        0.0        0.0   \n",
      "\n",
      "   Cartbuytoday  buy/brower  buy/collect  buy/cart  buy/sum  u_buy/u_brower  \\\n",
      "0           0.0         0.0          0.0       0.0      0.0             0.0   \n",
      "1           0.0         0.0          0.0       0.0      0.0             0.0   \n",
      "2           0.0         0.0          0.0       0.0      0.0             0.0   \n",
      "3           0.0         0.0          0.0       0.0      0.0             0.0   \n",
      "4           0.0         0.0          0.0       0.0      0.0             0.0   \n",
      "\n",
      "   u_buy/u_collect  u_buy/u_cart  Catrgory  \n",
      "0              0.0           0.0       0.0  \n",
      "1              0.0           0.0       0.0  \n",
      "2              0.0           0.0       0.0  \n",
      "3              0.0           0.0       0.0  \n",
      "4              0.0           0.0       0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率 0.00717221371585\n",
      "F1= 0.0142422787646\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=5, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris  \n",
    "from sklearn import neighbors  \n",
    "import sklearn \n",
    "train = pd.read_csv('C:/Users/zzq/Desktop/DataMining/Data/train.csv')\n",
    "test =  pd.read_csv('C:/Users/zzq/Desktop/DataMining/Data/test.csv')\n",
    "print test.head()\n",
    "train_x = train.iloc[:,[2,3,4,5,6,7,8,9,10,11,12,13]]\n",
    "train_y = train.loc[:,[\"Catrgory\"]]\n",
    "test_x = test.iloc[:,[2,3,4,5,6,7,8,9,10,11,12,13]]\n",
    "test_y = test.loc[:,[\"Catrgory\"]]\n",
    "knn = neighbors.KNeighborsClassifier(algorithm='auto',n_neighbors=10,leaf_size=5)  \n",
    "#训练数据集  \n",
    "knn.fit(train_x, train_y)  \n",
    "#预测  \n",
    "y = knn.predict_proba(test_x)  \n",
    "#print pd.DataFrame(y)\n",
    "test[\"predict\"] = y[:, 0]\n",
    "from __future__ import division\n",
    "PrecisionSet=test[test.predict >= 0.5]\n",
    "ConnectSet = PrecisionSet[(PrecisionSet[\"Catrgory\"]== 1) & (PrecisionSet[\"Catrgory\"] >= 0.5)]\n",
    "ReferenceSet = PrecisionSet[PrecisionSet[\"Catrgory\"]== 1]\n",
    "presicion = len(ConnectSet) / len(PrecisionSet)\n",
    "print \"准确率\",presicion\n",
    "recall = len(ConnectSet)/ len(ReferenceSet)\n",
    "F1 = 2*presicion*recall / (presicion+recall) \n",
    "print \"F1=\",F1\n",
    "print knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catrgory    float64\n",
      "dtype: object\n",
      "99\n",
      "100\n",
      "<xgboost.core.Booster object at 0x000000000CD10B38>\n",
      "F1= 0.10989010989\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "# -*- coding:utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "train = pd.read_csv('C:/Users/zzq/Desktop/DataMining/Data/train.csv')\n",
    "test =  pd.read_csv('C:/Users/zzq/Desktop/DataMining/Data/test.csv')\n",
    "train_x = train.iloc[:,[2,3,4,5,7,9,10,11,12,13]]\n",
    "train_y = train.loc[:,[\"Catrgory\"]]\n",
    "print train_y.dtypes\n",
    "test_x = test.iloc[:,[2,3,4,5,7,9,10,11,12,13]]\n",
    "test_y = test.loc[:,[\"Catrgory\"]]\n",
    "train_x.head()\n",
    "test_x.head()\n",
    "\n",
    "dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "dtest = xgb.DMatrix(test_x)\n",
    "num_round =100\n",
    "\n",
    "params={\n",
    "'booster':'gbtree',\n",
    "'objective': 'multi:softmax', #多分类的问题\n",
    "'num_class':10, # 类别数，与 multisoftmax 并用\n",
    "'gamma':0.1,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "'max_depth':4, # 构建树的深度，越大越容易过拟合\n",
    "'lambda':35,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "'colsample_bytree':0.7, # 生成树时进行的列采样\n",
    "'min_child_weight':1, \n",
    "# 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言\n",
    "#，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。\n",
    "#这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 \n",
    "'subsample':0.6, # 随机采样训练样本\n",
    "'silent':0 ,#设置成1则没有运行信息输出，最好是设置为0.\n",
    "'eta': 0.3, # 如同学习率\n",
    "'seed':1000,\n",
    "'nthread':4,# cpu 线程数\n",
    "'eval_metric':'auc',\n",
    "'n_estimators':2\n",
    "}\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_round)\n",
    "y = bst.predict(dtest)\n",
    "print bst.best_iteration\n",
    "print bst.best_ntree_limit\n",
    "test[\"predict\"] = y\n",
    "print bst\n",
    "#np.savetxt(\"C:\\Users\\zzq\\Desktop\\DataMining\\Data\\yy.csv\", y, delimiter=',')\n",
    "\n",
    "from __future__ import division\n",
    "PrecisionSet=test[test.predict>=0.5]\n",
    "ConnectSet = PrecisionSet[(PrecisionSet[\"Catrgory\"]== 1) & (PrecisionSet[\"predict\"] >= 0.5)]\n",
    "ReferenceSet = PrecisionSet[PrecisionSet[\"Catrgory\"]== 1]\n",
    "presicion = len(ConnectSet) / len(PrecisionSet)\n",
    "#print \"准确率\",presicion\n",
    "recall = len(ConnectSet)/ len(ReferenceSet)\n",
    "F1 = 2*presicion*recall / (presicion+recall) \n",
    "print \"F1=\",F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] H2O requires requests module of version 2.10 or newer. You have version 2.9.1.\n",
      "You can upgrade to the newest version of the module running from the command line\n",
      "    $ pip2 install --upgrade requests\n",
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n",
      "  Starting server from C:\\Anaconda2\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: c:\\users\\zzq\\appdata\\local\\temp\\tmpf_ufje\n",
      "  JVM stdout: c:\\users\\zzq\\appdata\\local\\temp\\tmpf_ufje\\h2o_zzq_started_from_python.out\n",
      "  JVM stderr: c:\\users\\zzq\\appdata\\local\\temp\\tmpf_ufje\\h2o_zzq_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n",
      "Warning: Your H2O cluster version is too old (6 months and 24 days)! Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>04 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.10.4.8</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>6 months and 24 days !!!</td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_zzq_udwuju</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>7.092 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.11 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O cluster uptime:         04 secs\n",
       "H2O cluster version:        3.10.4.8\n",
       "H2O cluster version age:    6 months and 24 days !!!\n",
       "H2O cluster name:           H2O_from_python_zzq_udwuju\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    7.092 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "Python version:             2.7.11 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "(4050, 10)\n",
      "{u'add_count': u'int', u'u_buy/u_collect': u'real', u'buy/cart': u'real', u'collect_count': u'int', u'buy/brower': u'real', u'buy/sum': u'real', u'buy_count': u'int', u'u_buy/u_brower': u'real', u'u_buy/u_cart': u'real', u'brows_count': u'int'}\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "No model trained yet\n",
      "\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  DRF_model_python_1513322812817_1\n",
      "\n",
      "\n",
      "ModelMetricsRegression: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0367540291866\n",
      "RMSE: 0.191713403774\n",
      "MAE: 0.0927176673221\n",
      "RMSLE: 0.133371347553\n",
      "Mean Residual Deviance: 0.0367540291866\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_mae</b></td>\n",
       "<td><b>training_deviance</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-12-15 15:26:59</td>\n",
       "<td> 0.032 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-12-15 15:26:59</td>\n",
       "<td> 0.166 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1872744</td>\n",
       "<td>0.0599275</td>\n",
       "<td>0.0350717</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-12-15 15:26:59</td>\n",
       "<td> 0.204 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.2824074</td>\n",
       "<td>0.1597970</td>\n",
       "<td>0.0797539</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-12-15 15:26:59</td>\n",
       "<td> 0.219 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.3060286</td>\n",
       "<td>0.1945843</td>\n",
       "<td>0.0936535</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-12-15 15:26:59</td>\n",
       "<td> 0.234 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.2678604</td>\n",
       "<td>0.1601606</td>\n",
       "<td>0.0717492</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-12-15 15:27:00</td>\n",
       "<td> 0.248 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.2444518</td>\n",
       "<td>0.1399144</td>\n",
       "<td>0.0597567</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-12-15 15:27:00</td>\n",
       "<td> 0.265 sec</td>\n",
       "<td>6.0</td>\n",
       "<td>0.2285348</td>\n",
       "<td>0.1263940</td>\n",
       "<td>0.0522282</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-12-15 15:27:00</td>\n",
       "<td> 0.277 sec</td>\n",
       "<td>7.0</td>\n",
       "<td>0.2174457</td>\n",
       "<td>0.1167641</td>\n",
       "<td>0.0472826</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-12-15 15:27:00</td>\n",
       "<td> 0.287 sec</td>\n",
       "<td>8.0</td>\n",
       "<td>0.2083756</td>\n",
       "<td>0.1093616</td>\n",
       "<td>0.0434204</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-12-15 15:27:00</td>\n",
       "<td> 0.298 sec</td>\n",
       "<td>9.0</td>\n",
       "<td>0.2033869</td>\n",
       "<td>0.1044428</td>\n",
       "<td>0.0413662</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-12-15 15:27:00</td>\n",
       "<td> 0.309 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.1987956</td>\n",
       "<td>0.1005148</td>\n",
       "<td>0.0395197</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-12-15 15:27:00</td>\n",
       "<td> 0.320 sec</td>\n",
       "<td>11.0</td>\n",
       "<td>0.1957211</td>\n",
       "<td>0.0978006</td>\n",
       "<td>0.0383068</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-12-15 15:27:00</td>\n",
       "<td> 0.331 sec</td>\n",
       "<td>12.0</td>\n",
       "<td>0.1933691</td>\n",
       "<td>0.0950145</td>\n",
       "<td>0.0373916</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-12-15 15:27:00</td>\n",
       "<td> 0.341 sec</td>\n",
       "<td>13.0</td>\n",
       "<td>0.1917134</td>\n",
       "<td>0.0927177</td>\n",
       "<td>0.0367540</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    number_of_trees    training_rmse    training_mae    training_deviance\n",
       "--  -------------------  ----------  -----------------  ---------------  --------------  -------------------\n",
       "    2017-12-15 15:26:59  0.032 sec   0                  nan              nan             nan\n",
       "    2017-12-15 15:26:59  0.166 sec   1                  0.187274         0.0599275       0.0350717\n",
       "    2017-12-15 15:26:59  0.204 sec   2                  0.282407         0.159797        0.0797539\n",
       "    2017-12-15 15:26:59  0.219 sec   3                  0.306029         0.194584        0.0936535\n",
       "    2017-12-15 15:26:59  0.234 sec   4                  0.26786          0.160161        0.0717492\n",
       "    2017-12-15 15:27:00  0.248 sec   5                  0.244452         0.139914        0.0597567\n",
       "    2017-12-15 15:27:00  0.265 sec   6                  0.228535         0.126394        0.0522282\n",
       "    2017-12-15 15:27:00  0.277 sec   7                  0.217446         0.116764        0.0472826\n",
       "    2017-12-15 15:27:00  0.287 sec   8                  0.208376         0.109362        0.0434204\n",
       "    2017-12-15 15:27:00  0.298 sec   9                  0.203387         0.104443        0.0413662\n",
       "    2017-12-15 15:27:00  0.309 sec   10                 0.198796         0.100515        0.0395197\n",
       "    2017-12-15 15:27:00  0.320 sec   11                 0.195721         0.0978006       0.0383068\n",
       "    2017-12-15 15:27:00  0.331 sec   12                 0.193369         0.0950145       0.0373916\n",
       "    2017-12-15 15:27:00  0.341 sec   13                 0.191713         0.0927177       0.036754"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>brows_count</td>\n",
       "<td>2984.0981445</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8759634</td></tr>\n",
       "<tr><td>u_buy/u_brower</td>\n",
       "<td>147.4749756</td>\n",
       "<td>0.0494203</td>\n",
       "<td>0.0432904</td></tr>\n",
       "<tr><td>u_buy/u_cart</td>\n",
       "<td>92.5609894</td>\n",
       "<td>0.0310181</td>\n",
       "<td>0.0271707</td></tr>\n",
       "<tr><td>add_count</td>\n",
       "<td>78.1993942</td>\n",
       "<td>0.0262054</td>\n",
       "<td>0.0229549</td></tr>\n",
       "<tr><td>buy/brower</td>\n",
       "<td>26.6418438</td>\n",
       "<td>0.0089279</td>\n",
       "<td>0.0078205</td></tr>\n",
       "<tr><td>collect_count</td>\n",
       "<td>22.1612225</td>\n",
       "<td>0.0074264</td>\n",
       "<td>0.0065053</td></tr>\n",
       "<tr><td>buy/cart</td>\n",
       "<td>20.7759953</td>\n",
       "<td>0.0069622</td>\n",
       "<td>0.0060987</td></tr>\n",
       "<tr><td>u_buy/u_collect</td>\n",
       "<td>17.0590687</td>\n",
       "<td>0.0057167</td>\n",
       "<td>0.0050076</td></tr>\n",
       "<tr><td>buy_count</td>\n",
       "<td>10.8327770</td>\n",
       "<td>0.0036302</td>\n",
       "<td>0.0031799</td></tr>\n",
       "<tr><td>buy/sum</td>\n",
       "<td>6.8425169</td>\n",
       "<td>0.0022930</td>\n",
       "<td>0.0020086</td></tr></table></div>"
      ],
      "text/plain": [
       "variable         relative_importance    scaled_importance    percentage\n",
       "---------------  ---------------------  -------------------  ------------\n",
       "brows_count      2984.1                 1                    0.875963\n",
       "u_buy/u_brower   147.475                0.0494203            0.0432904\n",
       "u_buy/u_cart     92.561                 0.0310181            0.0271707\n",
       "add_count        78.1994                0.0262054            0.0229549\n",
       "buy/brower       26.6418                0.00892794           0.00782055\n",
       "collect_count    22.1612                0.00742644           0.00650529\n",
       "buy/cart         20.776                 0.00696224           0.00609866\n",
       "u_buy/u_collect  17.0591                0.00571666           0.00500758\n",
       "buy_count        10.8328                0.00363017           0.00317989\n",
       "buy/sum          6.84252                0.00229299           0.00200858"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "准确率 0.0433604336043\n",
      "F1= 0.0831168831169\n"
     ]
    }
   ],
   "source": [
    "#H2ORandomForestEstimator\n",
    "# -*- coding:utf-8 -*-\n",
    "import h2o\n",
    "h2o.init()\n",
    "trainData = h2o.import_file(path=\"C:/Users/zzq/Desktop/DataMining/Data/train.csv\")\n",
    "\n",
    "temp = trainData[[2,3,4,5,7,9,10,11,12,13]]\n",
    "#temp = trainData[2:15]\n",
    "print temp.shape\n",
    "print temp.types\n",
    "temp.head()\n",
    "\n",
    "testData = h2o.import_file(path=\"C:/Users/zzq/Desktop/DataMining/Data/test.csv\")\n",
    "testData.head()\n",
    "\n",
    "import xgboost\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "model = H2ORandomForestEstimator(ntrees = 13, max_depth = 6,nbins = 60,seed=10)\n",
    "print model\n",
    "model.train(x=temp.names,y='Catrgory',training_frame=trainData)\n",
    "pre_tag=H2ORandomForestEstimator.predict(model ,testData)\n",
    "pre_tag.head()\n",
    "print model\n",
    "\n",
    "from __future__ import division\n",
    "PrecisionSet=testData.cbind(pre_tag[\"predict\"])\n",
    "PrecisionSet = PrecisionSet[PrecisionSet[\"predict\"]>=0.5]\n",
    "#h2o.export_file(all,\"C:/Users/zzq/Desktop/DataMining/Data/predict.csv\")\n",
    "ConnectSet = PrecisionSet[(PrecisionSet[\"Catrgory\"]== 1) & (PrecisionSet[\"predict\"] >= 0.5)]\n",
    "ReferenceSet = PrecisionSet[PrecisionSet[\"Catrgory\"]== 1]\n",
    "#aa=all[all[\"Catrgory\"]==all[\"predict\"],:]\n",
    "presicion = ConnectSet.nrow / PrecisionSet.nrow\n",
    "print \"准确率\",presicion\n",
    "recall = ConnectSet.nrow/ ReferenceSet.nrow\n",
    "F1 = 2*presicion*recall / (presicion+recall) \n",
    "print \"F1=\",F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4050, 15)\n",
      "(87454, 15)\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1000, splitter='best')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97997804560111601"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#jueceshu\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "train = pd.read_csv(\"C:/Users/zzq/Desktop/DataMining/Data/train.csv\")\n",
    "print train.shape\n",
    "train.head()\n",
    "\n",
    "test = pd.read_csv(\"C:/Users/zzq/Desktop/DataMining/Data/test.csv\")\n",
    "print test.shape\n",
    "test.head()\n",
    "\n",
    "train_x = train.iloc[:,[2,3,4,5,6,7,8,9,10,11,12,13]]\n",
    "train_y = train.loc[:,[\"Catrgory\"]]\n",
    "test_x = test.iloc[:,[2,3,4,5,6,7,8,9,10,11,12,13]]\n",
    "test_y = test.loc[:,[\"Catrgory\"]]\n",
    "\n",
    "\n",
    "from sklearn import tree  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=10,random_state=1000) \n",
    "clf.fit(train_x, train_y) \n",
    "print clf\n",
    "\n",
    "from __future__ import division\n",
    "Prediction = clf.predict(test_x)\n",
    "test[\"predict\"] = Prediction\n",
    "PrecisionSet=test[test.predict == 1]\n",
    "ConnectSet = test[(test[\"Catrgory\"]== 1) & (test[\"predict\"] == 1)]\n",
    "ReferenceSet = test[test[\"Catrgory\"]== 1]\n",
    "presicion = len(ConnectSet) / len(PrecisionSet)\n",
    "#print \"准确率\",presicion\n",
    "recall = len(ConnectSet)/ len(ReferenceSet)\n",
    "F1 = 2*presicion*recall / (presicion+recall) \n",
    "print \"F1=\",F1\n",
    "clf.score(test_x,test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
