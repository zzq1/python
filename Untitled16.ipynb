{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "data = pd.read_csv(\"C:/Users/zzq/Desktop/DataMining/Data/pythontest3/feature_temp.csv\")\n",
    "train = pd.read_csv(\"C:/Users/zzq/Desktop/DataMining/Data/pythontest3/train.csv\")\n",
    "test = pd.read_csv(\"C:/Users/zzq/Desktop/DataMining/Data/pythontest3/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:0.247504\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=1, shrinking=True, tol=0.001, verbose=False)\n",
      "准确率 0.0149769585253\n",
      "F1= 0.0294826364281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "train_x = train.iloc[:,2:61]\n",
    "train_y = train.iloc[:,[62]]\n",
    "test_x = test.iloc[:,2:61]\n",
    "test_y = test.iloc[:,[62]]\n",
    "\n",
    "from sklearn import svm \n",
    "clf = svm.SVR(max_iter=1) \n",
    "clf.fit(train_x, train_y)\n",
    "result = clf.predict(test_x)\n",
    "print \"MSE:%f\" % mean_squared_error(test_y, result, sample_weight=None, multioutput='uniform_average')\n",
    "print clf\n",
    "temp_test = test\n",
    "temp_test[\"predict\"] = result\n",
    "PrecisionSet=temp_test[temp_test.predict >= 0.5]\n",
    "ConnectSet = temp_test[(temp_test[\"target\"] == 1) & (temp_test[\"predict\"] >= 0.5)]\n",
    "ReferenceSet = temp_test[temp_test[\"target\"]== 1]\n",
    "presicion = len(ConnectSet) / len(PrecisionSet)\n",
    "print \"准确率\",presicion\n",
    "recall = len(ConnectSet)/ len(ReferenceSet)\n",
    "F1 = 2*presicion*recall / (presicion+recall) \n",
    "print \"F1=\",F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:0.032896\n",
      "AUC Score (Train): 0.754161\n",
      "F1= 0.157356412274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.py:451: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "rf0 = RandomForestClassifier(oob_score=True, random_state=20, max_depth = 10)   \n",
    "rf0.fit(train_x,train_y)\n",
    "#print rf0.oob_score_\n",
    "y_predprob = rf0.predict_proba(test_x)[:,1]\n",
    "print \"MSE:%f\" % mean_squared_error(test_y, y_predprob, sample_weight=None, multioutput='uniform_average')\n",
    "print \"AUC Score (Train): %f\" % roc_auc_score(test_y,y_predprob)\n",
    "#print precision_recall_fscore_support(test_y,y_predprob)\n",
    "\n",
    "temp_test = test\n",
    "temp_test[\"predict\"] = y_predprob\n",
    "PrecisionSet=temp_test[temp_test.predict >= 0.5]\n",
    "#PrecisionSet = temp_test\n",
    "ConnectSet = temp_test[(temp_test[\"target\"] == 1) & (temp_test[\"predict\"] >= 0.5)]\n",
    "ReferenceSet = temp_test[temp_test[\"target\"]== 1]\n",
    "#ReferenceSet = temp_test\n",
    "presicion = len(ConnectSet) / len(PrecisionSet)\n",
    "#print \"准确率\",presicion\n",
    "recall = len(ConnectSet)/ len(ReferenceSet)\n",
    "F1 = 2*presicion*recall / (presicion+recall) \n",
    "print \"F1=\",F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "100\n",
      "MSE:0.036041\n",
      "(array([ 0.98883391,  0.1241535 ]), array([ 0.974435  ,  0.24774775]), array([ 0.98158165,  0.16541353]), array([30354,   444], dtype=int64))\n",
      "F1= 0.165413533835\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "dtest = xgb.DMatrix(test_x)\n",
    "num_round =100\n",
    "\n",
    "params={\n",
    "'booster':'gbtree',\n",
    "'objective': 'multi:softmax', #多分类的问题\n",
    "'num_class':10, # 类别数，与 multisoftmax 并用\n",
    "'gamma':0.1,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "'max_depth':4, # 构建树的深度，越大越容易过拟合\n",
    "'lambda':35,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "'colsample_bytree':0.7, # 生成树时进行的列采样\n",
    "'min_child_weight':1, \n",
    "# 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言\n",
    "#，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。\n",
    "#这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 \n",
    "'subsample':0.6, # 随机采样训练样本\n",
    "'silent':0 ,#设置成1则没有运行信息输出，最好是设置为0.\n",
    "'eta': 0.3, # 如同学习率\n",
    "'seed':1000,\n",
    "'nthread':4,# cpu 线程数\n",
    "'eval_metric':'auc',\n",
    "'n_estimators':2\n",
    "}\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_round)\n",
    "y = bst.predict(dtest)\n",
    "print bst.best_iteration\n",
    "print bst.best_ntree_limit\n",
    "tmp_test = test\n",
    "tmp_test[\"predict\"] = y\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "print \"MSE:%f\" % mean_squared_error(test_y, y, sample_weight=None, multioutput='uniform_average')\n",
    "print precision_recall_fscore_support(test_y,y)\n",
    "\n",
    "from __future__ import division\n",
    "PrecisionSet=tmp_test[tmp_test.predict>=0.5]\n",
    "ConnectSet = tmp_test[(tmp_test[\"target\"]== 1) & (tmp_test[\"predict\"] >= 0.5)]\n",
    "ReferenceSet = tmp_test[tmp_test[\"target\"]== 1]\n",
    "presicion = len(ConnectSet) / len(PrecisionSet)\n",
    "#print \"准确率\",presicion\n",
    "recall = len(ConnectSet)/ len(ReferenceSet)\n",
    "F1 = 2*presicion*recall / (presicion+recall) \n",
    "print \"F1=\",F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "MSE:0.039580\n",
      "F1= 0.142153413089\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 3) \n",
    "clf.fit(train_x, train_y) \n",
    "y_pre = clf.predict(test_x)\n",
    "print clf\n",
    "#criterion='entropy', max_depth=2,random_state=500\n",
    "t_test = test\n",
    "t_test[\"predict\"] = y_pre\n",
    "print \"MSE:%f\" % mean_squared_error(test_y, y_pre, sample_weight=None, multioutput='uniform_average')\n",
    "from __future__ import division\n",
    "PrecisionSet=t_test[t_test.predict==1]\n",
    "ConnectSet = t_test[(t_test[\"target\"]== 1) & (t_test[\"predict\"] == 1)]\n",
    "ReferenceSet = t_test[t_test[\"target\"]== 1]\n",
    "presicion = len(ConnectSet) / len(PrecisionSet)\n",
    "#print \"准确率\",presicion\n",
    "recall = len(ConnectSet)/ len(ReferenceSet)\n",
    "F1 = 2*presicion*recall / (presicion+recall) \n",
    "print \"F1=\",F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:45: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val auc Score: 0.225732\n",
      "MSE: 0.819201\n",
      "val auc Score: 0.343136\n",
      "MSE: 0.841575\n",
      "Linear stretch of predictions to [0,1]\n",
      "blend result\n",
      "val auc Score: 0.337600\n",
      "MSE: 0.357757\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score,mean_squared_error\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "\n",
    "train = pd.read_csv(\"C:/Users/zzq/Desktop/DataMining/Data/pythontest3/train.csv\")\n",
    "test= pd.read_csv(\"C:/Users/zzq/Desktop/DataMining/Data/pythontest3/test.csv\")\n",
    "X = np.array(train.iloc[:,2:61])\n",
    "y = np.array(train.iloc[:,[62]])\n",
    "X_predict = np.array(test.iloc[:,2:61])\n",
    "y_predict = np.array(test.iloc[:,[62]])\n",
    "\n",
    "'''创建训练的数据集'''\n",
    "#data, target = make_blobs(n_samples=50000, centers=2, random_state=0, cluster_std=0.60)\n",
    "\n",
    "'''模型融合中使用到的各个单模型'''\n",
    "clfs = [RandomForestClassifier(),\n",
    "        DecisionTreeClassifier()]\n",
    "\n",
    "'''切分一部分数据作为测试集'''\n",
    "#X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.33, random_state=2017)\n",
    "\n",
    "\n",
    "dataset_blend_train = np.zeros((X.shape[0], len(clfs)))\n",
    "dataset_blend_test = np.zeros((X_predict.shape[0], len(clfs)))\n",
    "\n",
    "#n_folds = 5\n",
    "#skf = list(StratifiedKFold(y, n_folds))\n",
    "kf = KFold(n_splits=5,random_state=2017)\n",
    "for j, clf in enumerate(clfs):\n",
    "    dataset_blend_test_j = np.zeros((X_predict.shape[0],5))\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(y)):\n",
    "        X_train = X[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_submission = clf.predict_proba(X_test)[:, 0]\n",
    "        dataset_blend_train[test_index, j] = y_submission\n",
    "        dataset_blend_test_j[:, i] = clf.predict_proba(X_predict)[:, 0]\n",
    "    '''对于测试集，直接用这k个模型的预测值均值作为新的特征。'''\n",
    "    dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
    "    print(\"val auc Score: %f\" % roc_auc_score(y_predict, dataset_blend_test[:, j]))\n",
    "    print(\"MSE: %f\" % mean_squared_error(y_predict, dataset_blend_test[:, j]))\n",
    "clf = GradientBoostingClassifier(learning_rate=0.02, subsample=0.5, max_depth=6, n_estimators=30)\n",
    "#print pd.DataFrame(dataset_blend_train)\n",
    "clf.fit(dataset_blend_train, y)\n",
    "y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
    "#print pd.DataFrame(y_submission)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Linear stretch of predictions to [0,1]\")\n",
    "y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())\n",
    "print(\"blend result\")\n",
    "print(\"val auc Score: %f\" % (roc_auc_score(y_predict, y_submission)))\n",
    "print(\"MSE: %f\" % (mean_squared_error(y_predict, y_submission)))\n",
    "#print(\"MSE: %f\" % (precision_recall_fscore_support(y_predict, y_submission)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-fa77f5d5a68f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtt_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mPrecisionSet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtt_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtt_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mConnectSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtt_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtt_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"predict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mReferenceSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2667\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2669\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2671\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "tt_test = test\n",
    "from __future__ import division\n",
    "PrecisionSet=tt_test[tt_test.predict==1]\n",
    "ConnectSet = tt_test[(tt_test[\"target\"]== 1) & (tt_test[\"predict\"] == 1)]\n",
    "ReferenceSet = t_test[t_test[\"target\"]== 1]\n",
    "presicion = len(ConnectSet) / len(PrecisionSet)\n",
    "#print \"准确率\",presicion\n",
    "recall = len(ConnectSet)/ len(ReferenceSet)\n",
    "F1 = 2*presicion*recall / (presicion+recall) \n",
    "print \"F1=\",F1\n",
    "\n",
    "\n",
    "tt_test = test\n",
    "tt_test[\"predict\"] = y_submission\n",
    "from __future__ import division\n",
    "PrecisionSet=tt_test[tt_test.predict>=0.5]\n",
    "ConnectSet = tt_test[(tt_test[\"target\"]== 1) & (tt_test[\"predict\"] >= 0.5)]\n",
    "ReferenceSet = tt_test[tt_test[\"target\"]== 1]\n",
    "presicion = len(ConnectSet) / len(PrecisionSet)\n",
    "#print \"准确率\",presicion\n",
    "recall = len(ConnectSet)/ len(ReferenceSet)\n",
    "F1 = 2*presicion*recall / (presicion+recall) \n",
    "print \"F1=\",F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0217239363049\n",
      "F1= 0.157766990291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm \n",
    "from sklearn.metrics import roc_auc_score,mean_squared_error\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "\n",
    "train = pd.read_csv(\"C:/Users/zzq/Desktop/DataMining/Data/pythontest3/train.csv\")\n",
    "test= pd.read_csv(\"C:/Users/zzq/Desktop/DataMining/Data/pythontest3/test.csv\")\n",
    "train_x = np.array(train.iloc[:,2:61])\n",
    "train_y = np.array(train.iloc[:,[62]])\n",
    "test_x = np.array(test.iloc[:,2:61])\n",
    "test_y = np.array(test.iloc[:,[62]])\n",
    "import xgboost as xgb\n",
    "\"\"\" ### 融合方案--Averaging ### \"\"\"\n",
    "class Averaging(object):\n",
    "    def __init__(self,base_models, weights):\n",
    "        self.weights = weights\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, x_test):\n",
    "        df = pd.DataFrame()\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "            clf.fit(x_train, y_train)\n",
    "            pre = clf.predict(x_test)\n",
    "            df[i] = self.weights[i] * pre\n",
    "        df[\"sum\"] = 0\n",
    "        for n in range(len(self.base_models)):\n",
    "            df[\"sum\"] += df[n]\n",
    "        return list(df[\"sum\"])\n",
    "            \n",
    "ave = Averaging([xgb.XGBRegressor(),neighbors.KNeighborsRegressor(),RandomForestClassifier(random_state=200, max_depth = 3)],[0.3,0.3,0.4])\n",
    "predict = ave.fit_predict(train_x, train_y, test_x)\n",
    "tt_test = test\n",
    "tt_test[\"predict\"] = predict\n",
    "from __future__ import division\n",
    "PrecisionSet=tt_test[tt_test.predict>=0.5]\n",
    "ConnectSet = tt_test[(tt_test[\"target\"]== 1) & (tt_test[\"predict\"] >= 0.5)]\n",
    "ReferenceSet = tt_test[tt_test[\"target\"]== 1]\n",
    "presicion = len(ConnectSet) / len(PrecisionSet)\n",
    "recall = len(ConnectSet)/ len(ReferenceSet)\n",
    "F1 = 2*presicion*recall / (presicion+recall) \n",
    "print \"MSE:\",mean_squared_error(test_y, predict, sample_weight=None, multioutput='uniform_average')\n",
    "print \"F1=\",F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30798L, 1L)\n",
      "F1= 0.176204819277\n",
      "MSE: 0.035521787129\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>ubbclirate</th>\n",
       "      <th>ubbcolrate</th>\n",
       "      <th>ubbcarrate</th>\n",
       "      <th>ubbuyrate_60</th>\n",
       "      <th>ubclick_count_1</th>\n",
       "      <th>ubclick_count_7</th>\n",
       "      <th>ubclick_count_14</th>\n",
       "      <th>ubclick_count_28</th>\n",
       "      <th>...</th>\n",
       "      <th>bcart_count_1</th>\n",
       "      <th>bcart_count_7</th>\n",
       "      <th>bcart_count_14</th>\n",
       "      <th>bcart_count_28</th>\n",
       "      <th>bbclirate</th>\n",
       "      <th>bbcolrate</th>\n",
       "      <th>bbcarrate</th>\n",
       "      <th>bbuyrate_60</th>\n",
       "      <th>target</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30793</th>\n",
       "      <td>11169500.0</td>\n",
       "      <td>15584.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30794</th>\n",
       "      <td>11949750.0</td>\n",
       "      <td>28209.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30795</th>\n",
       "      <td>71250.0</td>\n",
       "      <td>28641.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30796</th>\n",
       "      <td>2076000.0</td>\n",
       "      <td>8549.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30797</th>\n",
       "      <td>3096750.0</td>\n",
       "      <td>20388.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  brand_id  ubbclirate  ubbcolrate  ubbcarrate  ubbuyrate_60  \\\n",
       "30793  11169500.0   15584.0         0.0         0.0         0.0           0.0   \n",
       "30794  11949750.0   28209.0         0.0         0.0         0.0           0.0   \n",
       "30795     71250.0   28641.0         0.0         0.0         0.0           0.0   \n",
       "30796   2076000.0    8549.0         0.0         0.0         0.0           0.0   \n",
       "30797   3096750.0   20388.0         0.0         0.0         0.0           0.0   \n",
       "\n",
       "       ubclick_count_1  ubclick_count_7  ubclick_count_14  ubclick_count_28  \\\n",
       "30793              0.0              0.0               0.0               0.0   \n",
       "30794              0.0              0.0               0.0               0.0   \n",
       "30795              0.0              0.0               0.0               0.0   \n",
       "30796              0.0              0.0               0.0               0.0   \n",
       "30797              0.0              0.0               0.0               0.0   \n",
       "\n",
       "        ...     bcart_count_1  bcart_count_7  bcart_count_14  bcart_count_28  \\\n",
       "30793   ...               0.0            0.0             0.0             0.0   \n",
       "30794   ...               0.0            0.0             0.0             0.0   \n",
       "30795   ...               0.0            0.0             0.0             0.0   \n",
       "30796   ...               0.0            1.0             1.0             1.0   \n",
       "30797   ...               0.0            0.0             0.0             0.0   \n",
       "\n",
       "       bbclirate  bbcolrate  bbcarrate  bbuyrate_60  target  predict  \n",
       "30793   0.000000        0.0        0.0     0.000000     0.0      0.0  \n",
       "30794   0.000000        0.0        0.0     0.000000     0.0      0.0  \n",
       "30795   0.022727        0.0        2.0     0.022472     0.0      0.0  \n",
       "30796   0.000000        0.0        0.0     0.000000     0.0      0.0  \n",
       "30797   0.000000        0.0        0.0     0.000000     0.0      0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score,mean_squared_error\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "\n",
    "train = pd.read_csv(\"C:/Users/zzq/Desktop/DataMining/Data/pythontest3/train.csv\")\n",
    "test= pd.read_csv(\"C:/Users/zzq/Desktop/DataMining/Data/pythontest3/test.csv\")\n",
    "train_x = np.array(train.iloc[:,2:61])\n",
    "train_y = np.array(train.iloc[:,[62]])\n",
    "test_x = np.array(test.iloc[:,2:61])\n",
    "test_y = np.array(test.iloc[:,[62]])\n",
    "print test_y.shape\n",
    "\n",
    "clfs = [xgb.XGBRegressor(max_depth=10),neighbors.KNeighborsRegressor(n_neighbors=10)]\n",
    "#随机森林\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf1 = RandomForestClassifier(oob_score=True, random_state=20, max_depth = 3)\n",
    "\n",
    "#xgboost\n",
    "import xgboost as xgb\n",
    "param_dist = {'booster':'gbtree',\n",
    "              'max_depth':3,\n",
    "              'objective':'reg:logistic',\n",
    "              'n_estimators':2}\n",
    "clf2 = xgb.XGBClassifier()\n",
    "\n",
    "from sklearn import tree  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf3 = tree.DecisionTreeClassifier(max_depth = 3) \n",
    "\n",
    "#融合模型\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "eclf1 = VotingClassifier(estimators=[('rf',RandomForestClassifier(max_depth = 3)),\n",
    "                                     ('xgb',xgb.XGBClassifier()),\n",
    "                                     ('dt',tree.DecisionTreeClassifier(max_depth = 3))],\n",
    "                         voting='soft')\n",
    "\n",
    "\n",
    "eclf1 = eclf1.fit(train_x,train_y)\n",
    "pre = eclf1.predict(test_x)\n",
    "pre = pd.DataFrame(pre,columns=['pre'])\n",
    "#print pd.DataFrame(pre)\n",
    "tt_test = test\n",
    "tt_test[\"predict\"] = pre\n",
    "from __future__ import division\n",
    "PrecisionSet=tt_test[tt_test.predict==1]\n",
    "ConnectSet = tt_test[(tt_test[\"target\"]== 1) & (tt_test[\"predict\"] == 1)]\n",
    "ReferenceSet = tt_test[tt_test[\"target\"]== 1]\n",
    "presicion = len(ConnectSet) / len(PrecisionSet)\n",
    "#print \"准确率\",presicion\n",
    "recall = len(ConnectSet)/ len(ReferenceSet)\n",
    "F1 = 2*presicion*recall / (presicion+recall) \n",
    "print \"F1=\",F1\n",
    "pre = pd.DataFrame(pre)\n",
    "print \"MSE:\",mean_squared_error(test_y, pre, sample_weight=None, multioutput='uniform_average')\n",
    "tt_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
